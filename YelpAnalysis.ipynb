{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YelpAnalysis.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "s9POGwhHuntk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Yelp Data Analysis**\n",
        "\n",
        "In this project we perform sentimental analysis on yelp data set (https://www.yelp.com/dataset ).\n",
        "\n",
        "review.json file is used to perform sentimental analysis on businesses.\n",
        "\n",
        "Only first 100000 (positive + negative) reviews are extracted from the dataset and analysis is performed.\n",
        "\n",
        "user ratings > 3 are positive else negative.\n",
        "\n",
        "Final classification accuracies by different models are reported :\n",
        "DENSE - Dense feed forward network\n",
        "RNN - Simple recurrent neural network \n",
        "LSTM - Long short term memory \n",
        "BI-LSTM - Bi directional LSTM \n",
        "RF - Random forest classifier\n",
        "SVM - Support vector machine eclassifier"
      ]
    },
    {
      "metadata": {
        "id": "yVbg8k2Quntn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Review JSON path"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0VeTc5Hyunto",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os,sys\n",
        "review_path = \"../input/yelp_academic_dataset_review.json\";\n",
        "if os.path.isfile(review_path):\n",
        "    pass\n",
        "else:\n",
        "    print(\"Invalid file path. Please place the python file in the same folder as review.json and rerun.\")\n",
        "    sys.exit(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pvBLjohOuntv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Required libraries"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OV-tYxdKuntw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords \n",
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, SimpleRNN, Bidirectional, Embedding, Dropout\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XFxlvKWyunt1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Read json"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LMxenZTuunt2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_records = 50000\n",
        "x_raw = []\n",
        "y_raw = []\n",
        "reviews = pd.read_json(review_path,lines=True,chunksize=max_records)\n",
        "pos = 0\n",
        "neg = 0\n",
        "for chunks in reviews:\n",
        "    for index, rec in chunks.iterrows():\n",
        "        y = rec[\"stars\"]\n",
        "        if pos < max_records and y > 3:            \n",
        "            pos = pos + 1\n",
        "            x_raw.append(rec[\"text\"])\n",
        "            y_raw.append(1)\n",
        "        elif neg < max_records:\n",
        "            neg = neg + 1\n",
        "            x_raw.append(rec[\"text\"])\n",
        "            y_raw.append(0)\n",
        "    if len(y_raw) == max_records*2:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r6DEAmOlunt6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Only first 150 words are used for review (**input_shape**).\n",
        "\n",
        "**vocab_len** is a parameter which is used to train Embedding layer whose size is equal to the number of unique words in sequences."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "yGwhaipGunt7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_shape = 150\n",
        "vocab_len = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cj_q0ummunt_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Stop words which doesn't add much meaning to the sequences are filtered.\n",
        "* Tokens are padded to same length and vectorized"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zuvWuRmaunuA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english')) \n",
        "x_text = []\n",
        "for w in x_raw:\n",
        "    arr = [s for s in text_to_word_sequence(w) if not s in stop_words]  \n",
        "    x_text.append(arr)\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(x_text)\n",
        "vocab_len = len(t.word_index) + 1\n",
        "\n",
        "sequences = t.texts_to_sequences(x_text)\n",
        "data = pad_sequences(sequences, maxlen=input_shape)\n",
        "labels = np.asarray(y_raw)\n",
        "\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EujL8DgMunuE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Split data into train, test and validation set."
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1dkYPOPaunuF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(data,labels,test_size=0.1,random_state=101)\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size=0.1,random_state=102)\n",
        "print('x_train:', x_train.shape)\n",
        "print('y_train:', y_train.shape)\n",
        "print('x_val:', x_val.shape)\n",
        "print('y_val:', y_val.shape)\n",
        "print('x_test:', x_test.shape)\n",
        "print('y_test:', y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V_U5FOqAunuJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Function return model of specified type\n",
        "\n",
        "* name: Name of the model \n",
        "* vocab_len : Embedding vocabulary size\n",
        "* inp_shape : Input shape"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "oER7VmK0unuK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def getModel(name,vocab_len,inp_shape):\n",
        "    if name == \"DENSE\":\n",
        "        model = Sequential()\n",
        "        model.add(Dense(128, activation='relu', input_shape=(inp_shape,)))\n",
        "        model.add(Dropout(0.1))\n",
        "        model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "        return model\n",
        "    elif name == \"RNN\":\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(vocab_len, 32))\n",
        "        model.add(SimpleRNN(64, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "        model.add(SimpleRNN(64, dropout=0.1, recurrent_dropout=0.1))\n",
        "        model.add(Dense(50, activation='relu'))\n",
        "        model.add(Dropout(0.1))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "        return model\n",
        "    elif name == \"LSTM\":\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(vocab_len, 32))\n",
        "        model.add(LSTM(64, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))\n",
        "        model.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1))\n",
        "        model.add(Dense(50, activation='relu'))\n",
        "        model.add(Dropout(0.1))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "        return model\n",
        "    elif name == \"BI-LSTM\":\n",
        "        model = Sequential()\n",
        "        model.add(Embedding(vocab_len, 32))\n",
        "        model.add(Bidirectional(LSTM(64, return_sequences=True,dropout=0.1, recurrent_dropout=0.1)))\n",
        "        model.add(Bidirectional(LSTM(64, dropout=0.1, recurrent_dropout=0.1)))\n",
        "        model.add(Dense(50, activation='relu'))\n",
        "        model.add(Dropout(0.1))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "        return model\n",
        "    elif name == \"RF\":\n",
        "        model = RandomForestClassifier()\n",
        "        return model\n",
        "    elif name == \"SVM\":\n",
        "        model = SVC(random_state=125)\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeFBfTkZunuP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Plot accuracies"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "iWZOdFf_unuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_accuracy(model_name,history):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "    plt.title(model_name+' - Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fn26Y3v-unuW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train model and predict accuracies"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "MryGqNzEunuX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_list = [\"DENSE\",\"RNN\",\"LSTM\",\"BI-LSTM\",\"RF\",\"SVM\"]\n",
        "model_accuracies = []\n",
        "cls_reports = []\n",
        "for name in model_list:\n",
        "    model = getModel(name,vocab_len,input_shape)\n",
        "    if name == \"DENSE\" or name == \"RNN\" or name == \"LSTM\" or name == \"BI-LSTM\":\n",
        "        history = model.fit(x_train, y_train,epochs=20,batch_size=128,validation_data=(x_val, y_val)) \n",
        "        plot_accuracy(name,history)\n",
        "        y_pred = model.predict_classes(x_test)        \n",
        "    elif name == \"RF\" or name == \"SVM\":\n",
        "        model.fit(x_train,y_train)\n",
        "        y_pred = model.predict(x_test)\n",
        "    model_accuracies.append(round(accuracy_score(y_test,y_pred)*100,2))\n",
        "    cls_reports.append(precision_recall_fscore_support(y_test,y_pred, average='micro'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "XAdT73mkunua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "print(\"Testing results:\")\n",
        "t = PrettyTable(['Model','Acuracy','Precision','Recall','F1-Score'])\n",
        "for a,b,c in zip(model_list,model_accuracies,cls_reports):\n",
        "    t.add_row([a,b,c[0],c[1],c[2]])\n",
        "print(t)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}